{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "'''*-----------------------------------------------------------------------*---\n",
    "                                                         Author: Jason Ma\n",
    "                                                         Date  : Jan 19 2019\n",
    "                              traffic-sign-classifier\n",
    "\n",
    "  File Name  : traffic-sign-classifier.py\n",
    "  Description: Trains CNN to classify traffic signs using the GTSRB dataset.\n",
    "---*-----------------------------------------------------------------------*'''\n",
    "\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39223, 32, 32) (39223,)\n",
      "(12630, 32, 32) (12630,)\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#global vars\n",
    "train_dir = 'GTSRB/train/'\n",
    "test_dir  = 'GTSRB/test/'\n",
    "img_shape = (32, 32)\n",
    "n_classes = 43\n",
    "\n",
    "train_imgs = []\n",
    "train_labels = []\n",
    "\n",
    "test_imgs = []\n",
    "test_labels = []\n",
    "\n",
    "#read in train data\n",
    "for i in range(n_classes):\n",
    "  csv_path = train_dir + str(i) + '/GT-' + \"%05d\" % (i) + '.csv'\n",
    "  #print(csv_path)\n",
    "  with open(csv_path, 'r') as f:\n",
    "    line = f.readline()\n",
    "    \n",
    "    for line in f:\n",
    "      line = line.strip().split(';')\n",
    "      full_path = train_dir + str(i) + \"/\" + line[0]\n",
    "      img = cv2.imread(full_path, 0)\n",
    "      img = cv2.resize(img, img_shape)\n",
    "      train_imgs.append(img)\n",
    "      train_labels.append(int(line[7]))\n",
    "      \n",
    "      '''\n",
    "      label = int(line[7])\n",
    "      if label == 14:\n",
    "        train_labels.append(1)\n",
    "      else:\n",
    "        train_labels.append(0)\n",
    "      '''\n",
    "\n",
    "#read in test data\n",
    "csv_path = test_dir + 'GT-final_test.csv'\n",
    "\n",
    "with open(csv_path, 'r') as f:\n",
    "  line = f.readline()\n",
    "  \n",
    "  for line in f:\n",
    "    line = line.strip().split(';')\n",
    "    full_path = test_dir + line[0]\n",
    "    img = cv2.imread(full_path, 0)\n",
    "    img = cv2.resize(img, img_shape)\n",
    "    test_imgs.append(img)\n",
    "    test_labels.append(int(line[7]))\n",
    "    \n",
    "    '''\n",
    "    label = int(line[7])\n",
    "    if label == 14:\n",
    "      test_labels.append(1)\n",
    "    else:\n",
    "      test_labels.append(0)\n",
    "    '''\n",
    "    \n",
    "\n",
    "#extend training set\n",
    "for i in range(70):\n",
    "  if i % 5 == 0:\n",
    "    img = cv2.imread(\"night/%d.png\" % (i), 0)\n",
    "    img = cv2.resize(img, img_shape)\n",
    "    train_imgs.append(img)\n",
    "    train_labels.append(14)\n",
    "    #train_labels.append(1)\n",
    "\n",
    "#allocate arrays for each dataset\n",
    "train_data = np.array(train_imgs)\n",
    "train_labels = np.array(train_labels)\n",
    "print(train_data.shape, train_labels.shape)\n",
    "\n",
    "test_data = np.array(test_imgs)\n",
    "test_labels = np.array(test_labels)\n",
    "print(test_data.shape, test_labels.shape)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Confusion(testData, testLabels, classifier):\n",
    "    \n",
    "    total_samples = len(testData)\n",
    "    \n",
    "    all_labels = list(set(testLabels))\n",
    "    \n",
    "    label_counts = {}\n",
    "    for l in all_labels:\n",
    "      label_counts[l] = 0\n",
    "      \n",
    "    M = np.zeros((len(all_labels), len(all_labels)))\n",
    "    \n",
    "    batchsize=50\n",
    "    correct=0.\n",
    "    for data,label in DataBatch(testData,testLabels,batchsize,shuffle=False):\n",
    "        prediction = classifier(data)\n",
    "        correct += np.sum(prediction==label)\n",
    "        \n",
    "        for i in range(len(prediction)):\n",
    "            M[label[i]][prediction[i]] += 1\n",
    "            label_counts[label[i]] += 1\n",
    "    \n",
    "    for y in range(M.shape[0]):\n",
    "      for x in range(M.shape[1]):\n",
    "        M[y][x] = M[y][x] / label_counts[all_labels[y]]\n",
    "    \n",
    "    accuracy = correct / total_samples\n",
    "    return M, accuracy\n",
    "\n",
    "def VisualizeConfusion(M):\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.imshow(M)\n",
    "    plt.show()\n",
    "    print(np.round(M,2))\n",
    "\n",
    "# a generator for batches of data\n",
    "# yields data (batchsize, 3, 32, 32) and labels (batchsize)\n",
    "# if shuffle, it will load batches in a random order\n",
    "def DataBatch(data, label, batchsize, shuffle=True):\n",
    "    n = data.shape[0]\n",
    "    if shuffle:\n",
    "        index = np.random.permutation(n)\n",
    "    else:\n",
    "        index = np.arange(n)\n",
    "    for i in range(int(np.ceil(n/batchsize))):\n",
    "        inds = index[i*batchsize : min(n,(i+1)*batchsize)]\n",
    "        yield data[inds], label[inds]\n",
    "\n",
    "# tests the accuracy of a classifier\n",
    "def test(testData, testLabels, classifier):\n",
    "    batchsize=50\n",
    "    correct=0.\n",
    "    for data,label in DataBatch(testData,testLabels,batchsize,shuffle=False):\n",
    "        prediction = classifier(data)\n",
    "        correct += np.sum(prediction==label)\n",
    "    return correct/testData.shape[0]*100\n",
    "\n",
    "  \n",
    "# helper function to get weight variable\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.01)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# helper function to get bias variable\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W, stride=2):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, stride, stride, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "class CNNClassifier():\n",
    "  def __init__(self, sess, graph, classes=2, n=5):\n",
    "    self.sess = sess\n",
    "    self.graph = graph\n",
    "  \n",
    "  def init(self, classes=43, n=5):\n",
    "    self.x = tf.placeholder(tf.float32, shape=[None,32,32,1], name='x') # input batch of images\n",
    "    self.y_ = tf.placeholder(tf.int64, shape=[None], name='y_') # input labels\n",
    "\n",
    "    # model variables\n",
    "    self.weights = {\n",
    "      'h1': tf.Variable(tf.truncated_normal(([4*4*n*4, 300]), stddev=0.01)),\n",
    "      'out': tf.Variable(tf.truncated_normal(([300, classes]), stddev=0.01)),\n",
    "    }\n",
    "    self.kernels = {\n",
    "      'c1': tf.Variable(tf.truncated_normal(([4,4,1,n]), stddev=0.01)),\n",
    "      'c2': tf.Variable(tf.truncated_normal(([4,4,n,n*2]), stddev=0.01)),\n",
    "      'c3': tf.Variable(tf.truncated_normal(([4,4,n*2,n*4]), stddev=0.01)),\n",
    "    }\n",
    "    self.biases = {\n",
    "      'h1': tf.Variable(tf.constant(0.0001, shape=([300]))),\n",
    "      'out': tf.Variable(tf.constant(0.0001, shape=([classes])))\n",
    "    }\n",
    "\n",
    "    # linear operation\n",
    "    #conv, relu, max\n",
    "    self.c1 = conv2d(self.x, self.kernels['c1'])\n",
    "    self.r1 = tf.nn.relu(self.c1)\n",
    "    self.m1 = tf.nn.max_pool(self.r1, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "    #conv, relu, max\n",
    "    self.c2 = conv2d(self.r1, self.kernels['c2'])\n",
    "    self.r2 = tf.nn.relu(self.c2)\n",
    "    self.m2 = tf.nn.max_pool(self.r2, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "    #conv, relu, max\n",
    "    self.c3 = conv2d(self.r2, self.kernels['c3'])\n",
    "    self.r3 = tf.nn.relu(self.c3)\n",
    "    self.m3 = tf.nn.max_pool(self.r3, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "    #fc\n",
    "    self.h1 = tf.matmul(tf.reshape(self.r3, (-1,4*4*n*4)), self.weights['h1']) + self.biases['h1']\n",
    "    #fc\n",
    "    self.y = tf.matmul(tf.reshape(self.h1,(-1,300)),self.weights['out']) + self.biases['out']\n",
    "\n",
    "    #tf.reset_default_graph()\n",
    "    self.prediction = tf.argmax(self.y,1)\n",
    "    self.cross_entropy = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=self.y_, logits=self.y))\n",
    "    self.train_step = tf.train.AdamOptimizer(1e-4).minimize(self.cross_entropy)\n",
    "    self.correct_prediction = tf.equal(self.prediction, self.y_)\n",
    "    self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n",
    "\n",
    "    self.sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "  def train(self, trainData, trainLabels, epochs=1, batchsize=50):\n",
    "    for epoch in range(epochs):\n",
    "      for i, (data,label) in enumerate(DataBatch(trainData, trainLabels, batchsize, shuffle=True)):\n",
    "        data=np.expand_dims(data,-1)\n",
    "        _, acc = self.sess.run([self.train_step, self.accuracy], feed_dict={self.x: data, self.y_: label})\n",
    "\n",
    "      print ('Epoch:%d Accuracy: %f'%(epoch+1, test(test_data, test_labels, self)))\n",
    "  \n",
    "  def save(self, fname):\n",
    "    print(\"Saving\")\n",
    "    cwd = os.getcwd()\n",
    "    path = os.path.join(cwd, fname)\n",
    "    shutil.rmtree(path, ignore_errors=True)\n",
    "            \n",
    "    inputs = {\n",
    "      \"x\": self.x,\n",
    "      \"y_\": self.y_\n",
    "    }\n",
    "    \n",
    "    outputs = {\n",
    "      \"y\": self.y\n",
    "    }\n",
    "    \n",
    "    tf.saved_model.simple_save(self.sess, path, inputs, outputs)\n",
    "\n",
    "  def load(self, fname):\n",
    "    #self.saver = tf.train.import_meta_graph(fname)\n",
    "    #self.saver.restore(self.sess, tf.train.latest_checkpoint('./'))\n",
    "    tf.saved_model.loader.load(self.sess, [tf.saved_model.tag_constants.SERVING], fname)\n",
    "    \n",
    "    self.x = self.graph.get_tensor_by_name('x:0')\n",
    "    self.y_ = self.graph.get_tensor_by_name('y_:0')\n",
    "    self.prediction = self.graph.get_tensor_by_name('ArgMax:0')\n",
    "\n",
    "  def __call__(self, x):\n",
    "    return self.sess.run(self.prediction, feed_dict={self.x: np.expand_dims(x,-1)})\n",
    "\n",
    "  def get_first_layer_weights(self):\n",
    "    return self.sess.run(self.weights[0])\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start model\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "  sess = tf.Session(graph=graph)\n",
    "  cnnClassifier = CNNClassifier(sess, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 Accuracy: 32.351544\n",
      "Epoch:2 Accuracy: 61.710214\n",
      "Epoch:3 Accuracy: 69.041964\n",
      "Epoch:4 Accuracy: 72.557403\n",
      "Epoch:5 Accuracy: 74.916865\n",
      "Epoch:6 Accuracy: 76.476643\n",
      "Epoch:7 Accuracy: 77.577197\n",
      "Epoch:8 Accuracy: 79.881235\n",
      "Epoch:9 Accuracy: 79.287411\n",
      "Epoch:10 Accuracy: 80.506730\n",
      "Saving\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/saved_model/simple_save.py:85: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Pass your op to the equivalent parameter main_op instead.\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /home/jam/projects/traffic-classifier/model-cccff/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "#train and save model\n",
    "with graph.as_default():\n",
    "  cnnClassifier.init()\n",
    "  cnnClassifier.train(train_data, train_labels, epochs=10)\n",
    "  cnnClassifier.save('model-cccff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 Accuracy: 82.573238\n",
      "Epoch:2 Accuracy: 83.515439\n",
      "Epoch:3 Accuracy: 83.380839\n",
      "Epoch:4 Accuracy: 84.497229\n",
      "Epoch:5 Accuracy: 81.314331\n",
      "Epoch:6 Accuracy: 83.942993\n",
      "Epoch:7 Accuracy: 84.766429\n",
      "Epoch:8 Accuracy: 83.752969\n",
      "Epoch:9 Accuracy: 83.855899\n",
      "Epoch:10 Accuracy: 83.950911\n",
      "Saving\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /home/jam/projects/traffic-classifier/model-cccff/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "#additional training and saving\n",
    "with graph.as_default():\n",
    "  cnnClassifier.train(train_data, train_labels, epochs=10)\n",
    "  cnnClassifier.save('model-cccff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model-cccff/variables/variables\n"
     ]
    }
   ],
   "source": [
    "#load model params\n",
    "with graph.as_default():\n",
    "  cnnClassifier.load('model-cccff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc:  0.8395091053048298\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.45 0.52 0.   ... 0.   0.   0.  ]\n",
      " [0.02 0.9  0.04 ... 0.   0.   0.  ]\n",
      " [0.   0.06 0.82 ... 0.   0.   0.  ]\n",
      " ...\n",
      " [0.01 0.02 0.   ... 0.44 0.   0.01]\n",
      " [0.   0.   0.   ... 0.   0.78 0.13]\n",
      " [0.   0.   0.   ... 0.   0.   0.99]]\n"
     ]
    }
   ],
   "source": [
    "M, acc = Confusion(test_data, test_labels, cnnClassifier)\n",
    "print(\"Acc: \", acc)\n",
    "VisualizeConfusion(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 [14]\n",
      "6 [14]\n",
      "7 [14]\n",
      "8 [14]\n",
      "10 [14]\n",
      "14 [14]\n",
      "15 [14]\n",
      "16 [14]\n",
      "17 [14]\n",
      "21 [14]\n",
      "22 [14]\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "def test_img(f, classifier):\n",
    "  img = cv2.imread(f, 0)\n",
    "  img = cv2.resize(img, img_shape)\n",
    "  \n",
    "  #kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
    "  #img = cv2.filter2D(img, -1, kernel)\n",
    "  \n",
    "  #img = cv2.bilateralFilter(img, 5, 25, 25)\n",
    "  \n",
    "  imgs = []\n",
    "  imgs.append(img)\n",
    "  imgs = np.array(imgs)\n",
    "  prediction = classifier(imgs)\n",
    "  return prediction\n",
    "\n",
    "count = 0\n",
    "for i in range(23):\n",
    "  #if i % 5 != 0:\n",
    "  pred = test_img(\"screen/%d.png\" % (i), cnnClassifier)\n",
    "\n",
    "  if pred[0] == 14:\n",
    "    print(i, pred)\n",
    "    count += 1\n",
    "    \n",
    "print(count)\n",
    "\n",
    "#for i in range(10):\n",
    "#  for j in range(10):\n",
    "#    print(test_img(\"GTSRB/train/%d/%05d_%05d.ppm\" % (14, i, j), cnnClassifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
